# approach2_simple_anomaly.py
"""
–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ 2: –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π —Å –ø–æ–º–æ—â—å—é Autoencoders
(–ù–µ —Ç—Ä–µ–±—É–µ—Ç anomalib)
"""
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score
import pandas as pd
import time
from tqdm import tqdm


class Autoencoder(nn.Module):
    """–ü—Ä–æ—Å—Ç–æ–π –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π"""

    def __init__(self, input_dim=224):
        super(Autoencoder, self).__init__()

        # –≠–Ω–∫–æ–¥–µ—Ä
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),  # 112x112
            nn.ReLU(),
            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # 56x56
            nn.ReLU(),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # 28x28
            nn.ReLU(),
            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),  # 14x14
            nn.ReLU(),
        )

        # –î–µ–∫–æ–¥–µ—Ä
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),  # 28x28
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),  # 56x56
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),  # 112x112
            nn.ReLU(),
            nn.ConvTranspose2d(32, 3, kernel_size=3, stride=2, padding=1, output_padding=1),  # 224x224
            nn.Sigmoid(),
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded


class AnomalyDataset(Dataset):
    """–î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π"""

    def __init__(self, normal_dir, anomaly_dirs=None, transform=None, is_train=True):
        self.transform = transform
        self.is_train = is_train

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        normal_path = Path(normal_dir)
        self.normal_images = list(normal_path.glob('*.jpg'))

        # –î–ª—è –æ–±—É—á–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ
        if is_train:
            self.images = self.normal_images
            self.labels = [0] * len(self.images)  # 0 = –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ
        else:
            # –î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–æ–±–∞–≤–ª—è–µ–º –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ
            self.anomaly_images = []
            if anomaly_dirs:
                for dir_path in anomaly_dirs:
                    anomaly_path = Path(dir_path)
                    if anomaly_path.exists():
                        self.anomaly_images.extend(list(anomaly_path.glob('*.jpg')))

            self.images = self.normal_images + self.anomaly_images
            self.labels = [0] * len(self.normal_images) + [1] * len(self.anomaly_images)

        print(f"{'Train' if is_train else 'Test'}: {len(self.normal_images)} –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö, "
              f"{len(self.anomaly_images) if not is_train else 0} –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö")

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path = self.images[idx]
        label = self.labels[idx]

        image = Image.open(img_path).convert('RGB')

        if self.transform:
            image = self.transform(image)

        return image, label, str(img_path)


def train_autoencoder():
    """–û–±—É—á–µ–Ω–∏–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞ –Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö"""
    print("=" * 60)
    print("–ü–û–î–•–û–î 2: –û–ë–ù–ê–†–£–ñ–ï–ù–ò–ï –ê–ù–û–ú–ê–õ–ò–ô (Autoencoder)")
    print("=" * 60)

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
    BATCH_SIZE = 32
    IMG_SIZE = 224
    EPOCHS = 50
    LEARNING_RATE = 0.001

    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º—ã
    transform = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
    ])

    # –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (—Ç–æ–ª—å–∫–æ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ)
    train_dataset = AnomalyDataset(
        normal_dir="data/classification/train/no_defect",
        transform=transform,
        is_train=True
    )

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)

    # –î–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ + –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ)
    test_dataset = AnomalyDataset(
        normal_dir="data/classification/test/no_defect",
        anomaly_dirs=[
            "data/classification/test/crack",
            "data/classification/test/dent",
            "data/classification/test/scratch"
        ],
        transform=transforms.Compose([
            transforms.Resize((IMG_SIZE, IMG_SIZE)),
            transforms.ToTensor(),
        ]),
        is_train=False
    )

    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)

    # –ú–æ–¥–µ–ª—å –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = Autoencoder().to(device)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    # –û–±—É—á–µ–Ω–∏–µ
    print("\nüéØ –û–±—É—á–µ–Ω–∏–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞ –Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö...")
    train_losses = []

    for epoch in range(EPOCHS):
        model.train()
        running_loss = 0.0

        pbar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{EPOCHS}')
        for images, _, _ in pbar:
            images = images.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, images)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            pbar.set_postfix({'Loss': running_loss / len(pbar)})

        epoch_loss = running_loss / len(train_loader)
        train_losses.append(epoch_loss)

        if (epoch + 1) % 10 == 0:
            print(f"Epoch {epoch + 1}/{EPOCHS}, Loss: {epoch_loss:.6f}")

    print(f"\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. Final loss: {train_losses[-1]:.6f}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    torch.save(model.state_dict(), "models/autoencoder_model.pth")

    return model, device, test_loader, train_losses


def evaluate_anomaly_detection(model, device, test_loader):
    """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π"""
    print("\nüîç –û—Ü–µ–Ω–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π...")

    model.eval()
    all_scores = []
    all_labels = []

    with torch.no_grad():
        for images, labels, _ in tqdm(test_loader, desc="–û—Ü–µ–Ω–∫–∞"):
            images = images.to(device)

            # –†–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
            reconstructed = model(images)

            # –í—ã—á–∏—Å–ª—è–µ–º MSE –º–µ–∂–¥—É –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º –∏ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π
            mse = torch.mean((images - reconstructed) ** 2, dim=[1, 2, 3])

            all_scores.extend(mse.cpu().numpy())
            all_labels.extend(labels.numpy())

    all_scores = np.array(all_scores)
    all_labels = np.array(all_labels)

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º scores
    all_scores = (all_scores - all_scores.min()) / (all_scores.max() - all_scores.min() + 1e-8)

    return all_scores, all_labels


def calculate_metrics(scores, labels):
    """–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π"""
    print("\nüìä –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫...")

    # ROC-AUC
    roc_auc = roc_auc_score(labels, scores)

    # Precision-Recall AUC
    pr_auc = average_precision_score(labels, scores)

    # –ù–∞—Ö–æ–¥–∏–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
    precisions, recalls, thresholds = precision_recall_curve(labels, scores)
    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-8)
    optimal_idx = np.argmax(f1_scores)
    optimal_threshold = thresholds[optimal_idx] if optimal_idx < len(thresholds) else 0.5

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º
    predictions = (scores > optimal_threshold).astype(int)

    # Basic metrics
    accuracy = np.mean(predictions == labels)
    precision = np.sum((predictions == 1) & (labels == 1)) / (np.sum(predictions == 1) + 1e-8)
    recall = np.sum((predictions == 1) & (labels == 1)) / (np.sum(labels == 1) + 1e-8)
    f1 = 2 * (precision * recall) / (precision + recall + 1e-8)

    print(f"ROC-AUC: {roc_auc:.4f}")
    print(f"PR-AUC: {pr_auc:.4f}")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1-Score: {f1:.4f}")
    print(f"Optimal threshold: {optimal_threshold:.4f}")

    return {
               'roc_auc': roc_auc,
               'pr_auc': pr_auc,
               'accuracy': accuracy,
               'precision': precision,
               'recall': recall,
               'f1_score': f1,
               'optimal_threshold': optimal_threshold,
               'optimal_f1': f1_scores[optimal_idx]
           }, scores, labels, predictions


def visualize_results(scores, labels, metrics, train_losses):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    Path("results/anomaly").mkdir(exist_ok=True)

    fig, axes = plt.subplots(2, 3, figsize=(15, 10))

    # 1. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ anomaly scores
    normal_scores = scores[labels == 0]
    anomaly_scores = scores[labels == 1]

    axes[0, 0].hist(normal_scores, bins=30, alpha=0.7, label='Normal', color='green')
    axes[0, 0].hist(anomaly_scores, bins=30, alpha=0.7, label='Anomaly', color='red')
    axes[0, 0].axvline(metrics['optimal_threshold'], color='black', linestyle='--',
                       label=f"Threshold: {metrics['optimal_threshold']:.3f}")
    axes[0, 0].set_xlabel('Anomaly Score')
    axes[0, 0].set_ylabel('Frequency')
    axes[0, 0].set_title('Distribution of Anomaly Scores')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)

    # 2. Loss during training
    axes[0, 1].plot(train_losses)
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Reconstruction Loss')
    axes[0, 1].set_title('Training Loss (Autoencoder)')
    axes[0, 1].grid(True, alpha=0.3)

    # 3. ROC Curve
    from sklearn.metrics import roc_curve
    fpr, tpr, _ = roc_curve(labels, scores)

    axes[0, 2].plot(fpr, tpr, color='darkorange', lw=2,
                    label=f'ROC curve (AUC = {metrics["roc_auc"]:.3f})')
    axes[0, 2].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    axes[0, 2].set_xlim([0.0, 1.0])
    axes[0, 2].set_ylim([0.0, 1.05])
    axes[0, 2].set_xlabel('False Positive Rate')
    axes[0, 2].set_ylabel('True Positive Rate')
    axes[0, 2].set_title('ROC Curve')
    axes[0, 2].legend(loc="lower right")
    axes[0, 2].grid(True, alpha=0.3)

    # 4. Precision-Recall Curve
    from sklearn.metrics import precision_recall_curve
    precision, recall, _ = precision_recall_curve(labels, scores)

    axes[1, 0].plot(recall, precision, color='blue', lw=2,
                    label=f'PR curve (AUC = {metrics["pr_auc"]:.3f})')
    axes[1, 0].set_xlim([0.0, 1.0])
    axes[1, 0].set_ylim([0.0, 1.05])
    axes[1, 0].set_xlabel('Recall')
    axes[1, 0].set_ylabel('Precision')
    axes[1, 0].set_title('Precision-Recall Curve')
    axes[1, 0].legend(loc="lower left")
    axes[1, 0].grid(True, alpha=0.3)

    # 5. Confusion Matrix
    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
    predictions = (scores > metrics['optimal_threshold']).astype(int)
    cm = confusion_matrix(labels, predictions)

    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normal', 'Anomaly'])
    disp.plot(ax=axes[1, 1], cmap='Blues')
    axes[1, 1].set_title(f'Confusion Matrix (threshold={metrics["optimal_threshold"]:.3f})')

    # 6. –ü—Ä–∏–º–µ—Ä—ã —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
    axes[1, 2].axis('off')
    axes[1, 2].text(0.5, 0.5, '–ü—Ä–∏–º–µ—Ä—ã —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π\n–±—É–¥—É—Ç –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ñ–∞–π–ª–µ',
                    horizontalalignment='center', verticalalignment='center',
                    transform=axes[1, 2].transAxes, fontsize=12)

    plt.tight_layout()
    plt.savefig("results/anomaly/anomaly_detection_results.png", dpi=150, bbox_inches='tight')
    plt.show()

    # –û—Ç–¥–µ–ª—å–Ω–æ: –ø—Ä–∏–º–µ—Ä—ã —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
    plot_reconstruction_examples()


def plot_reconstruction_examples():
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π"""
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
    ])

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = Autoencoder().to(device)
    model.load_state_dict(torch.load("models/autoencoder_model.pth", map_location=device))
    model.eval()

    # –í—ã–±–∏—Ä–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    test_images = []
    test_labels = []

    # –ù–æ—Ä–º–∞–ª—å–Ω–æ–µ
    normal_dir = Path("data/classification/test/no_defect")
    if normal_dir.exists():
        normal_imgs = list(normal_dir.glob('*.jpg'))[:2]
        test_images.extend(normal_imgs)
        test_labels.extend(['normal'] * 2)

    # –ê–Ω–æ–º–∞–ª—å–Ω—ã–µ
    for defect_dir in ["crack", "dent", "scratch"]:
        defect_path = Path("data/classification/test") / defect_dir
        if defect_path.exists():
            defect_imgs = list(defect_path.glob('*.jpg'))[:1]
            test_images.extend(defect_imgs)
            test_labels.extend([defect_dir] * 1)

    # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
    fig, axes = plt.subplots(len(test_images), 3, figsize=(10, len(test_images) * 3))

    if len(test_images) == 1:
        axes = axes.reshape(1, -1)

    for idx, (img_path, label) in enumerate(zip(test_images, test_labels)):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img = Image.open(img_path).convert('RGB')
        img_tensor = transform(img).unsqueeze(0).to(device)

        # –†–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
        with torch.no_grad():
            reconstructed = model(img_tensor)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        original_img = img_tensor[0].cpu().permute(1, 2, 0).numpy()
        recon_img = reconstructed[0].cpu().permute(1, 2, 0).numpy()

        # –†–∞–∑–Ω–∏—Ü–∞
        diff_img = np.abs(original_img - recon_img)
        diff_img = diff_img / diff_img.max()  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º
        axes[idx, 0].imshow(original_img)
        axes[idx, 0].set_title(f"Original: {label}")
        axes[idx, 0].axis('off')

        axes[idx, 1].imshow(recon_img)
        axes[idx, 1].set_title("Reconstructed")
        axes[idx, 1].axis('off')

        axes[idx, 2].imshow(diff_img, cmap='hot')
        axes[idx, 2].set_title("Difference (anomaly)")
        axes[idx, 2].axis('off')

    plt.suptitle('–ü—Ä–∏–º–µ—Ä—ã —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞', fontsize=14)
    plt.tight_layout()
    plt.savefig("results/anomaly/reconstruction_examples.png", dpi=150, bbox_inches='tight')
    plt.show()


def save_results(metrics, training_time):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    results = {
        'approach': 'Anomaly Detection (Autoencoder)',
        'model': 'Simple Autoencoder',
        'training_time': training_time,
        'metrics': metrics
    }

    import json
    with open("results/anomaly/anomaly_results.json", "w") as f:
        json.dump(results, f, indent=2)

    # –¢–∞–∫–∂–µ –≤ CSV –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    df = pd.DataFrame([metrics])
    df.to_csv("results/anomaly/anomaly_metrics.csv", index=False)

    print(f"\nüìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
    print("   - models/autoencoder_model.pth")
    print("   - results/anomaly/anomaly_results.json")
    print("   - results/anomaly/anomaly_metrics.csv")
    print("   - results/anomaly/anomaly_detection_results.png")
    print("   - results/anomaly/reconstruction_examples.png")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("=" * 60)
    print("–ó–ê–ü–£–°–ö –ü–û–î–•–û–î–ê 2: –û–ë–ù–ê–†–£–ñ–ï–ù–ò–ï –ê–ù–û–ú–ê–õ–ò–ô")
    print("=" * 60)

    start_time = time.time()

    # 1. –û–±—É—á–µ–Ω–∏–µ
    model, device, test_loader, train_losses = train_autoencoder()

    training_time = time.time() - start_time
    print(f"\n‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {training_time:.2f} —Å–µ–∫—É–Ω–¥")

    # 2. –û—Ü–µ–Ω–∫–∞
    scores, labels = evaluate_anomaly_detection(model, device, test_loader)

    # 3. –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
    metrics, scores, labels, predictions = calculate_metrics(scores, labels)

    # 4. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    visualize_results(scores, labels, metrics, train_losses)

    # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    save_results(metrics, training_time)

    print("\n" + "=" * 60)
    print("–ü–û–î–•–û–î 2 –ó–ê–í–ï–†–®–ï–ù")
    print("=" * 60)

    return metrics


if __name__ == "__main__":
    metrics = main()