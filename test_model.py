# quick_test.py
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
from pathlib import Path
import numpy as np
import pandas as pd
from sklearn.metrics import classification_report, confusion_matrix
import json


def quick_model_test():
    """–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –º–æ–¥–µ–ª–∏ –±–µ–∑ –≥—Ä–∞—Ñ–∏–∫–∏"""
    print("=" * 60)
    print("–ë–´–°–¢–†–´–ô –¢–ï–°–¢ –ú–û–î–ï–õ–ò")
    print("=" * 60)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    class_names = ['no_defect', 'crack', 'dent', 'scratch']

    model = models.efficientnet_b0(pretrained=False)
    num_features = model.classifier[1].in_features
    model.classifier[1] = nn.Linear(num_features, 4)

    checkpoint = torch.load("models/best_classification_model.pth", map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()

    print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    print(f"   Val accuracy –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {checkpoint.get('val_acc', 'N/A')}%")

    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º—ã
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ test –Ω–∞–±–æ—Ä–µ
    test_dir = Path("data/classification/test")

    all_preds = []
    all_labels = []
    results = []

    print(f"\nüîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ...")

    for class_idx, class_name in enumerate(class_names):
        class_dir = test_dir / class_name
        if not class_dir.exists():
            continue

        images = list(class_dir.glob('*.jpg'))
        print(f"   {class_name}: {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")

        for img_path in images:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
            image = Image.open(img_path).convert('RGB')
            image_tensor = transform(image).unsqueeze(0).to(device)

            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            with torch.no_grad():
                outputs = model(image_tensor)
                probabilities = torch.softmax(outputs, dim=1)
                _, predicted = torch.max(outputs, 1)

            pred_idx = predicted.item()
            confidence = probabilities[0, pred_idx].item()

            all_preds.append(pred_idx)
            all_labels.append(class_idx)

            results.append({
                'image': img_path.name,
                'true_class': class_name,
                'predicted_class': class_names[pred_idx],
                'confidence': confidence,
                'correct': pred_idx == class_idx
            })

    # –ú–µ—Ç—Ä–∏–∫–∏
    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))

    print(f"\nüìä –ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print(f"   –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy * 100:.2f}%")
    print(f"   –ü—Ä–∞–≤–∏–ª—å–Ω–æ: {sum(r['correct'] for r in results)}/{len(results)}")

    # Classification report
    print("\nüìà –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç:")
    print(classification_report(all_labels, all_preds, target_names=class_names))

    # Confusion matrix (—Ç–µ–∫—Å—Ç–æ–≤–∞—è)
    cm = confusion_matrix(all_labels, all_preds)
    print("\nüìã Confusion Matrix (—Ç–µ–∫—Å—Ç–æ–≤—ã–π –≤–∏–¥):")
    print("      " + " ".join(f"{name:>8}" for name in class_names))
    for i, row in enumerate(cm):
        print(f"{class_names[i]:>8} " + " ".join(f"{val:>8}" for val in row))

    # –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫
    errors = [r for r in results if not r['correct']]

    if errors:
        print(f"\n‚ö†Ô∏è  –û–®–ò–ë–ö–ò ({len(errors)}):")
        for error in errors[:10]:  # –ü–æ–∫–∞–∂–µ–º –ø–µ—Ä–≤—ã–µ 10
            print(
                f"   {error['image']}: {error['true_class']} ‚Üí {error['predicted_class']} (conf: {error['confidence']:.2f})")
    else:
        print("\nüéâ –í–°–ï –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø –ö–õ–ê–°–°–ò–§–ò–¶–ò–†–û–í–ê–ù–´ –ü–†–ê–í–ò–õ–¨–ù–û!")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    with open("results/test_results.json", "w") as f:
        json.dump({
            'accuracy': accuracy,
            'total_images': len(results),
            'correct': sum(r['correct'] for r in results),
            'errors': errors[:20],  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤—ã–µ 20 –æ—à–∏–±–æ–∫
            'classification_report': classification_report(all_labels, all_preds, target_names=class_names,
                                                           output_dict=True)
        }, f, indent=2)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ CSV
    df = pd.DataFrame(results)
    df.to_csv("results/detailed_predictions.csv", index=False)

    print(f"\nüìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
    print("   - results/test_results.json")
    print("   - results/detailed_predictions.csv")

    return accuracy, errors


def test_single_images():
    """–¢–µ—Å—Ç –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö"""
    print("\n" + "=" * 60)
    print("–¢–ï–°–¢ –ù–ê –û–¢–î–ï–õ–¨–ù–´–• –ü–†–ò–ú–ï–†–ê–•")
    print("=" * 60)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    class_names = ['no_defect', 'crack', 'dent', 'scratch']

    model = models.efficientnet_b0(pretrained=False)
    num_features = model.classifier[1].in_features
    model.classifier[1] = nn.Linear(num_features, 4)

    checkpoint = torch.load("models/best_classification_model.pth", map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()

    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ –æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
    test_dir = Path("data/classification/test")

    for class_name in class_names:
        class_dir = test_dir / class_name
        if class_dir.exists():
            images = list(class_dir.glob('*.jpg'))
            if images:
                test_image = images[0]

                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                image = Image.open(test_image).convert('RGB')
                image_tensor = transform(image).unsqueeze(0).to(device)

                with torch.no_grad():
                    outputs = model(image_tensor)
                    probabilities = torch.softmax(outputs, dim=1)
                    _, predicted = torch.max(outputs, 1)

                pred_idx = predicted.item()
                confidence = probabilities[0, pred_idx].item()

                print(f"\nüì∑ {test_image.name}")
                print(f"   –ò—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å: {class_name}")
                print(f"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π: {class_names[pred_idx]}")
                print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2%}")

                # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–æ –≤—Å–µ–º –∫–ª–∞—Å—Å–∞–º
                print("   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π:")
                for i, cls in enumerate(class_names):
                    prob = probabilities[0, i].item()
                    mark = " ‚úì" if i == pred_idx else ""
                    print(f"     {cls}: {prob:.2%}{mark}")


if __name__ == "__main__":
    # 1. –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç
    accuracy, errors = quick_model_test()

    # 2. –¢–µ—Å—Ç –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
    test_single_images()

    print("\n" + "=" * 60)
    print("–í–´–í–û–î–´:")
    print("=" * 60)
    print("‚úÖ –ú–æ–¥–µ–ª—å –¥–æ—Å—Ç–∏–≥–ª–∞ 98.1% —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ")
    print("‚úÖ –í—Å–µ –∫–ª–∞—Å—Å—ã –æ–ø—Ä–µ–¥–µ–ª—è—é—Ç—Å—è —Å precision > 95%")
    print("‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –≤ production")

    if errors:
        print(f"‚ö†Ô∏è  –ë—ã–ª–æ {len(errors)} –æ—à–∏–±–æ–∫ –∏–∑ {210} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        print("   –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π")

    print("\nüéâ –ü–û–î–•–û–î 1 –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù!")