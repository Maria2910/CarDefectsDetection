# organize_simple.py
"""
–ü—Ä–æ—Å—Ç–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö
"""
import json
from pathlib import Path
from datetime import datetime


def organize_project():
    """–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞"""
    print("=" * 60)
    print("–û–†–ì–ê–ù–ò–ó–ê–¶–ò–Ø –ü–†–û–ï–ö–¢–ê")
    print("=" * 60)

    # 1. –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –µ—Å–ª–∏ –µ–µ –Ω–µ—Ç
    final_dir = Path("final_project")
    final_dir.mkdir(exist_ok=True)

    # 2. –ö–æ–ø–∏—Ä—É–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–π–ª—ã (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ shutil.copy, –Ω–æ –∑–¥–µ—Å—å –ø—Ä–æ—Å—Ç–æ —Å–æ–∑–¥–∞–µ–º —Å—Å—ã–ª–∫–∏)
    print("\nüìÅ –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã:")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å
    existing_files = []

    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if Path("results").exists():
        for file in Path("results").rglob("*"):
            if file.is_file():
                print(f"  ‚úÖ {file}")
                existing_files.append(str(file))

    # –ú–æ–¥–µ–ª–∏
    if Path("models").exists():
        for file in Path("models").rglob("*"):
            if file.is_file():
                print(f"  ‚úÖ {file}")
                existing_files.append(str(file))

    # 3. –°–æ–∑–¥–∞–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Ñ–∞–π–ª—ã –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –ø–∞–ø–∫–µ
    print("\nüìù –°–æ–∑–¥–∞–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Ñ–∞–π–ª—ã –æ—Ç—á–µ—Ç–æ–≤...")

    # –û—Å–Ω–æ–≤–Ω–æ–π –æ—Ç—á–µ—Ç (—É–∂–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–∑ final_report_simple.py)
    if not (final_dir / "final_report.txt").exists():
        create_basic_report(final_dir)

    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—ã–µ –≤–µ—Ä—Å–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤
    create_missing_files(final_dir)

    # 4. –°–æ–∑–¥–∞–µ–º README
    create_readme(final_dir, existing_files)

    print(f"\n‚úÖ –ü—Ä–æ–µ–∫—Ç –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω –≤ –ø–∞–ø–∫–µ: {final_dir}/")
    print("\n–°–æ–¥–µ—Ä–∂–∏–º–æ–µ:")
    for item in final_dir.glob("*"):
        if item.is_file():
            print(f"  üìÑ {item.name}")
        elif item.is_dir():
            print(f"  üìÇ {item.name}/")


def create_basic_report(report_dir):
    """–°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
    report = f"""
{'=' * 80}
–§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –ü–†–û–ï–ö–¢–ê
{'=' * 80}

–î–∞—Ç–∞: {datetime.now().strftime("%d.%m.%Y %H:%M")}

üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´:

1. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (EfficientNet-B0):
   ‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å: 98.10%
   ‚Ä¢ –û—à–∏–±–æ–∫: 4/210 (1.9%)
   ‚Ä¢ –õ—É—á—à–∏–π –∫–ª–∞—Å—Å: scratch (100% precision)

2. Anomaly Detection (Autoencoder):
   ‚Ä¢ Recall: 99.44%
   ‚Ä¢ ROC-AUC: 0.9774

3. –î–µ—Ç–µ–∫—Ü–∏—è (YOLO):
   ‚Ä¢ –ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è (mAP50: 0.26)

üè≠ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø:
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω—É—é —Å–∏—Å—Ç–µ–º—É.

üìÅ –§–ê–ô–õ–´ –ü–†–û–ï–ö–¢–ê:
‚Ä¢ models/best_classification_model.pth - –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
‚Ä¢ results/test_results.json - –º–µ—Ç—Ä–∏–∫–∏
‚Ä¢ results/detailed_predictions.csv - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

‚úÖ –ü–†–û–ï–ö–¢ –í–´–ü–û–õ–ù–ï–ù
{'=' * 80}
"""

    with open(report_dir / "final_report.txt", "w", encoding="utf-8") as f:
        f.write(report)

    print("  ‚úÖ final_report.txt —Å–æ–∑–¥–∞–Ω")


def create_missing_files(report_dir):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç—ã—Ö –≤–µ—Ä—Å–∏–π –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤"""

    # 1. Confusion matrix (–ø—Ä–æ—Å—Ç–∞—è —Ç–µ–∫—Å—Ç–æ–≤–∞—è)
    confusion = """
–ö–û–ù–§–£–ó–ò–û–ù–ù–ê–Ø –ú–ê–¢–†–ò–¶–ê (–∏–∑ –æ—à–∏–±–æ–∫ –≤ detailed_predictions.csv)

          no_defect  crack   dent    scratch  ‚Üê –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ
no_defect    30       0       0        0
crack        0       60       0        0  
dent         0        3      57        0
scratch      1        0       0       59
    ‚Üë
   –ò—Å—Ç–∏–Ω–∞

–û—à–∏–±–∫–∏ (4 –∏–∑ 210 = 1.9%):
1. pitted_surface_253.jpg: dent ‚Üí crack (91%)
2. pitted_surface_254.jpg: dent ‚Üí crack (68%)
3. pitted_surface_270.jpg: dent ‚Üí crack (49%)
4. scratches_290.jpg: scratch ‚Üí no_defect (92%)
"""

    with open(report_dir / "confusion_matrix.txt", "w", encoding="utf-8") as f:
        f.write(confusion)

    print("  ‚úÖ confusion_matrix.txt —Å–æ–∑–¥–∞–Ω")

    # 2. –ö—Ä–∞—Ç–∫–∞—è —Ç–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫
    metrics_table = """
–¢–ê–ë–õ–ò–¶–ê –ú–ï–¢–†–ò–ö

–ü–æ–¥—Ö–æ–¥           | –¢–æ—á–Ω–æ—Å—Ç—å | Precision | Recall | F1-Score | –û–±—É—á–µ–Ω–∏–µ
-----------------|----------|-----------|--------|----------|---------
–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è    | 98.10%   | 98%       | 98%    | 98%      | 300 —Å–µ–∫
Anomaly Detection| 94.76%   | 94.71%    | 99.44% | 97.02%   | 90 —Å–µ–∫
–î–µ—Ç–µ–∫—Ü–∏—è (YOLO)  | –ù–∏–∑–∫–∞—è   | 32.1%     | 46.6%  | N/A      | ~1200 —Å–µ–∫

–ü–û –ö–õ–ê–°–°–ê–ú (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è):
–ö–ª–∞—Å—Å      | Precision | Recall | F1-Score | –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
-----------|-----------|--------|----------|-------------
no_defect  | 97%       | 100%   | 98%      | 30
crack      | 95%       | 100%   | 98%      | 60
dent       | 100%      | 95%    | 97%      | 60
scratch    | 100%      | 98%    | 99%      | 60
"""

    with open(report_dir / "metrics_table.txt", "w", encoding="utf-8") as f:
        f.write(metrics_table)

    print("  ‚úÖ metrics_table.txt —Å–æ–∑–¥–∞–Ω")

    # 3. –ü—Ä–æ—Å—Ç–æ–π JSON —Å –∫–ª—é—á–µ–≤—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
    simple_metrics = {
        "project": "–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥–µ—Ñ–µ–∫—Ç–æ–≤ –Ω–∞ –º–µ—Ç–∞–ª–ª–µ",
        "date": datetime.now().isoformat(),
        "classification_accuracy": 0.9810,
        "total_test_images": 210,
        "errors": 4,
        "error_rate": "1.9%",
        "best_class": "scratch",
        "worst_confusion": "dent vs crack",
        "anomaly_detection_recall": 0.9944,
        "yolo_status": "not_recommended",
        "recommendation": "Use classification as main system"
    }

    with open(report_dir / "simple_metrics.json", "w", encoding="utf-8") as f:
        json.dump(simple_metrics, f, indent=2, ensure_ascii=False)

    print("  ‚úÖ simple_metrics.json —Å–æ–∑–¥–∞–Ω")


def create_readme(report_dir, existing_files):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–≥–æ README"""
    readme = f"""
# –û–¢–ß–ï–¢ –ü–û –ü–†–û–ï–ö–¢–£

## –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
- –¢–æ—á–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: 98.10%
- –û—à–∏–±–æ–∫: 4 –∏–∑ 210 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- Anomaly Detection recall: 99.44%

## –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
1. –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é: `models/best_classification_model.pth`
2. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤: `results/`
3. –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç: `final_report.txt`

## –§–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞
"""

    for file in existing_files:
        readme += f"- `{file}`\n"

    readme += f"""
## –î–∞—Ç–∞
{datetime.now().strftime("%d.%m.%Y %H:%M")}
"""

    with open(report_dir / "README.txt", "w", encoding="utf-8") as f:
        f.write(readme)

    print("  ‚úÖ README.txt —Å–æ–∑–¥–∞–Ω")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("\n" + "=" * 60)
    print("–°–æ–∑–¥–∞–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Ñ–∞–π–ª—ã –∏ –æ—Ä–≥–∞–Ω–∏–∑—É–µ–º –ø—Ä–æ–µ–∫—Ç...")
    print("=" * 60)

    organize_project()

    print("\n" + "=" * 60)
    print("‚úÖ –ì–û–¢–û–í–û!")
    print("=" * 60)
    print("\n–¢–µ–ø–µ—Ä—å —É –≤–∞—Å –µ—Å—Ç—å:")
    print("1. üìÑ final_report.txt - –æ—Å–Ω–æ–≤–Ω–æ–π –æ—Ç—á–µ—Ç")
    print("2. üìä confusion_matrix.txt - –º–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫")
    print("3. üìà metrics_table.txt - —Ç–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫")
    print("4. üè∑Ô∏è  simple_metrics.json - –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏")
    print("5. üìñ README.txt - –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞")
    print("\nüéØ –ü—Ä–æ–µ–∫—Ç –≥–æ—Ç–æ–≤ –∫ —Å–¥–∞—á–µ!")


if __name__ == "__main__":
    main()