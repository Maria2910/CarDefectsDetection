# visualize_predictions.py
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–¥–ø–∏—Å—è–º–∏ –∫–ª–∞—Å—Å–æ–≤
"""
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image, ImageDraw, ImageFont
import numpy as np
from pathlib import Path
from datetime import datetime
import json
import os


class PredictionVisualizer:
    def __init__(self, model_path="models/best_classification_model.pth"):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.class_names = ['no_defect', 'crack', 'dent', 'scratch']
        self.class_display_names = ['–ù–æ—Ä–º–∞', '–¢—Ä–µ—â–∏–Ω–∞', '–í–º—è—Ç–∏–Ω–∞', '–¶–∞—Ä–∞–ø–∏–Ω–∞']

        print(f"üé® –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π...")
        print(f"   –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
        print(f"   –ö–ª–∞—Å—Å—ã: {self.class_display_names}")

        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        self.model = models.efficientnet_b0(pretrained=False)
        num_features = self.model.classifier[1].in_features
        self.model.classifier[1] = nn.Linear(num_features, 4)

        try:
            checkpoint = torch.load(model_path, map_location=self.device)
            self.model.load_state_dict(checkpoint['model_state_dict'])
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {model_path}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            print("   –°–æ–∑–¥–∞–µ–º –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å...")
            self._init_demo_model()

        self.model.to(self.device)
        self.model.eval()

        # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º—ã
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])

        # –¶–≤–µ—Ç–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤
        self.class_colors = {
            'no_defect': (0, 255, 0),  # –ó–µ–ª–µ–Ω—ã–π - –Ω–æ—Ä–º–∞
            'crack': (255, 0, 0),  # –ö—Ä–∞—Å–Ω—ã–π - —Ç—Ä–µ—â–∏–Ω–∞
            'dent': (255, 165, 0),  # –û—Ä–∞–Ω–∂–µ–≤—ã–π - –≤–º—è—Ç–∏–Ω–∞
            'scratch': (0, 0, 255)  # –°–∏–Ω–∏–π - —Ü–∞—Ä–∞–ø–∏–Ω–∞
        }

    def _init_demo_model(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π)"""

        def init_weights(m):
            if isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, mean=0.0, std=0.01)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)

        self.model.apply(init_weights)

    def predict_image(self, image_path):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
            image = Image.open(image_path).convert('RGB')
            original_size = image.size

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
            display_image = image.copy()

            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            image_tensor = self.transform(image).unsqueeze(0).to(self.device)

            with torch.no_grad():
                outputs = self.model(image_tensor)
                probabilities = torch.softmax(outputs, dim=1)
                _, predicted = torch.max(outputs, 1)

            class_idx = predicted.item()
            confidence = probabilities[0, class_idx].item()

            result = {
                'image_path': str(image_path),
                'image_name': Path(image_path).name,
                'predicted_class': self.class_names[class_idx],
                'predicted_class_display': self.class_display_names[class_idx],
                'confidence': confidence,
                'all_probabilities': probabilities.cpu().numpy()[0].tolist(),
                'original_size': original_size
            }

            return result, display_image

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {image_path}: {e}")
            return None, None

    def add_prediction_label(self, image, prediction_result):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ–¥–ø–∏—Å–∏ —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"""
        try:
            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –¥–ª—è —Ä–∏—Å–æ–≤–∞–Ω–∏—è
            draw = ImageDraw.Draw(image)

            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–µ–∫—Å—Ç–∞
            class_name = prediction_result['predicted_class_display']
            confidence = prediction_result['confidence']
            color = self.class_colors[prediction_result['predicted_class']]

            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
            text = f"{class_name}: {confidence:.1%}"

            # –í—ã–±–∏—Ä–∞–µ–º —Ä–∞–∑–º–µ—Ä —à—Ä–∏—Ñ—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            img_width, img_height = image.size
            font_size = max(20, img_width // 30)

            try:
                # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —à—Ä–∏—Ñ—Ç (—Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ Windows)
                font = ImageFont.truetype("arial.ttf", font_size)
            except:
                # –ï—Å–ª–∏ —à—Ä–∏—Ñ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π
                font = ImageFont.load_default()

            # –ü–æ–∑–∏—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ (–ª–µ–≤—ã–π –≤–µ—Ä—Ö–Ω–∏–π —É–≥–æ–ª)
            text_position = (10, 10)

            # –†–∏—Å—É–µ–º —Ñ–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            text_bbox = draw.textbbox(text_position, text, font=font)
            padding = 5
            background_box = (
                text_bbox[0] - padding,
                text_bbox[1] - padding,
                text_bbox[2] + padding,
                text_bbox[3] + padding
            )
            draw.rectangle(background_box, fill=(0, 0, 0, 128))  # –ü–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π —á–µ—Ä–Ω—ã–π

            # –†–∏—Å—É–µ–º —Ç–µ–∫—Å—Ç
            draw.text(text_position, text, font=font, fill=color)

            # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –ø—Ä–∞–≤—ã–π –Ω–∏–∂–Ω–∏–π —É–≥–æ–ª
            if prediction_result['confidence'] < 0.6:
                warning_text = "–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"
                warning_position = (img_width - 200, img_height - 40)
                draw.text(warning_position, warning_text, font=font, fill=(255, 255, 0))

            return image

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –ø–æ–¥–ø–∏—Å–∏: {e}")
            return image

    def process_validation_folder(self, input_folder="data/classification/val",
                                  output_folder="validation_predictions"):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –ø–∞–ø–∫–µ"""
        print(f"\nüìÇ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑: {input_folder}")

        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        output_path = Path(output_folder)
        output_path.mkdir(exist_ok=True)

        # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–ø–∞–ø–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤
        for class_name in self.class_names:
            (output_path / class_name).mkdir(exist_ok=True)

        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = {
            'total_processed': 0,
            'by_class': {cls: 0 for cls in self.class_names},
            'low_confidence': 0,
            'timestamp': datetime.now().isoformat()
        }

        # –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        all_results = []

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –ø–∞–ø–∫—É —Å –∫–ª–∞—Å—Å–æ–º
        for class_idx, class_name in enumerate(self.class_names):
            class_folder = Path(input_folder) / class_name

            if not class_folder.exists():
                print(f"‚ö†Ô∏è  –ü–∞–ø–∫–∞ {class_folder} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue

            images = list(class_folder.glob('*.jpg'))
            print(f"\n   üìÅ {self.class_display_names[class_idx]} ({class_name}): {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ (–¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)
            sample_size = min(10, len(images))
            for i, img_path in enumerate(images[:sample_size]):
                print(f"      –û–±—Ä–∞–±–æ—Ç–∫–∞ {i + 1}/{sample_size}: {img_path.name}", end='\r')

                # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                result, image = self.predict_image(img_path)

                if result and image:
                    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–ø–∏—Å—å –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    labeled_image = self.add_prediction_label(image, result)

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    output_filename = f"{class_name}_{img_path.stem}_predicted.jpg"
                    output_filepath = output_path / class_name / output_filename
                    labeled_image.save(output_filepath, quality=95)

                    # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    result['true_class'] = class_name
                    result['true_class_display'] = self.class_display_names[class_idx]
                    result['correct'] = (result['predicted_class'] == class_name)

                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    stats['total_processed'] += 1
                    stats['by_class'][result['predicted_class']] += 1

                    if result['confidence'] < 0.6:
                        stats['low_confidence'] += 1

                    all_results.append(result)

            print()  # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ø–æ—Å–ª–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self._save_statistics(stats, all_results, output_path)

        print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print(f"   üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {stats['total_processed']}")
        print(f"   üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_folder}")

        return all_results, stats

    def _save_statistics(self, stats, results, output_path):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        # JSON —Ñ–∞–π–ª —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        detailed_results = {
            'metadata': {
                'timestamp': stats['timestamp'],
                'total_images': stats['total_processed'],
                'model_used': 'EfficientNet-B0'
            },
            'statistics': stats,
            'predictions': results
        }

        with open(output_path / "predictions_detailed.json", 'w', encoding='utf-8') as f:
            json.dump(detailed_results, f, indent=2, ensure_ascii=False)

        # –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç
        report = f"""
–û–¢–ß–ï–¢ –ü–û –í–ê–õ–ò–î–ê–¶–ò–û–ù–ù–´–ú –î–ê–ù–ù–´–ú
–î–∞—Ç–∞: {datetime.now().strftime('%d.%m.%Y %H:%M')}
–ú–æ–¥–µ–ª—å: EfficientNet-B0

üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:
‚Ä¢ –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['total_processed']} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
‚Ä¢ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é (<60%): {stats['low_confidence']}

üìà –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô:
"""

        for class_name, count in stats['by_class'].items():
            display_name = self.class_display_names[self.class_names.index(class_name)]
            report += f"  ‚Ä¢ {display_name}: {count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n"

        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        if results:
            correct = sum(1 for r in results if r['correct'])
            accuracy = correct / len(results)

            report += f"""
üéØ –¢–û–ß–ù–û–°–¢–¨ –ù–ê –í–ê–õ–ò–î–ê–¶–ò–ò:
‚Ä¢ –ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {correct}/{len(results)}
‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.2%}

üìÅ –°–¢–†–£–ö–¢–£–†–ê –ü–ê–ü–û–ö:
‚Ä¢ validation_predictions/ - –∫–æ—Ä–Ω–µ–≤–∞—è –ø–∞–ø–∫–∞
  ‚îú‚îÄ‚îÄ no_defect/ - –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–∞–∫ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ
  ‚îú‚îÄ‚îÄ crack/ - –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–∞–∫ —Ç—Ä–µ—â–∏–Ω—ã
  ‚îú‚îÄ‚îÄ dent/ - –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–∞–∫ –≤–º—è—Ç–∏–Ω—ã
  ‚îú‚îÄ‚îÄ scratch/ - –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–∞–∫ —Ü–∞—Ä–∞–ø–∏–Ω—ã
  ‚îú‚îÄ‚îÄ predictions_detailed.json - –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
  ‚îî‚îÄ‚îÄ validation_report.txt - —ç—Ç–æ—Ç –æ—Ç—á–µ—Ç
"""

        with open(output_path / "validation_report.txt", 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}/validation_report.txt")


def create_sample_images_if_needed():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –µ—Å–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç"""
    val_path = Path("data/classification/val")

    if not val_path.exists():
        print("‚ö†Ô∏è  –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, —Å–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")

        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
        for class_name in ['no_defect', 'crack', 'dent', 'scratch']:
            class_dir = val_path / class_name
            class_dir.mkdir(parents=True, exist_ok=True)

            # –°–æ–∑–¥–∞–µ–º –ø–æ 2 —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
            for i in range(2):
                # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–µ —Ü–≤–µ—Ç–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                from PIL import Image, ImageDraw
                img = Image.new('RGB', (224, 224), color=(100, 100, 100))
                draw = ImageDraw.Draw(img)

                # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∫—É –∫–ª–∞—Å—Å–∞
                draw.text((10, 10), f"Test {class_name} {i + 1}", fill=(255, 255, 255))

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º
                img.save(class_dir / f"test_{class_name}_{i + 1}.jpg")

        print(f"‚úÖ –°–æ–∑–¥–∞–Ω—ã —Ç–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ {val_path}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("=" * 70)
    print("üé® –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô –ù–ê –í–ê–õ–ò–î–ê–¶–ò–û–ù–ù–´–• –î–ê–ù–ù–´–•")
    print("=" * 70)

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    create_sample_images_if_needed()

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    visualizer = PredictionVisualizer()

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    print("\n" + "=" * 70)
    print("1. –û–ë–†–ê–ë–û–¢–ö–ê –í–ê–õ–ò–î–ê–¶–ò–û–ù–ù–´–• –î–ê–ù–ù–´–•")
    print("=" * 70)

    results, stats = visualizer.process_validation_folder(
        input_folder="data/classification/val",
        output_folder="validation_predictions"
    )

    # –ü—Ä–∏–º–µ—Ä –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    print("\n" + "=" * 70)
    print("2. –ü–†–ò–ú–ï–†–´ –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô")
    print("=" * 70)

    # –ò—â–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    val_path = Path("data/classification/val")
    example_images = []

    if val_path.exists():
        for class_name in visualizer.class_names:
            class_dir = val_path / class_name
            if class_dir.exists():
                images = list(class_dir.glob('*.jpg'))
                if images:
                    example_images.append(images[0])

    if example_images:
        print(f"\nüîç –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è {len(example_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:")

        for img_path in example_images[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
            result, image = visualizer.predict_image(img_path)

            if result:
                print(f"\nüì∑ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {result['image_name']}")
                print(f"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å: {result['predicted_class_display']}")
                print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.2%}")

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å –∏–∑ –ø—É—Ç–∏
                true_class = img_path.parent.name
                true_display = visualizer.class_display_names[visualizer.class_names.index(true_class)]
                print(f"   –ò—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å: {true_display}")

                if result['predicted_class'] == true_class:
                    print("   ‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–µ—Ä–Ω–æ–µ!")
                else:
                    print("   ‚ùå –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–µ–≤–µ—Ä–Ω–æ–µ")

    print("\n" + "=" * 70)
    print("‚úÖ –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!")
    print("=" * 70)

    print(f"\nüìÅ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–û–•–†–ê–ù–ï–ù–´ –í –ü–ê–ü–ö–ï: validation_predictions/")
    print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"   ‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {stats['total_processed']}")
    print(f"   ‚Ä¢ –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {stats['low_confidence']}")

    print("\nüéØ –ö–ê–ö –ò–°–ü–û–õ–¨–ó–û–í–ê–¢–¨ –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print("""
1. –û—Ç–∫—Ä–æ–π—Ç–µ –ø–∞–ø–∫—É 'validation_predictions/'
2. –í –∫–∞–∂–¥–æ–π –ø–æ–¥–ø–∞–ø–∫–µ (no_defect, crack, dent, scratch) –Ω–∞—Ö–æ–¥—è—Ç—Å—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
3. –ù–∞ –∫–∞–∂–¥–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –µ—Å—Ç—å –ø–æ–¥–ø–∏—Å—å —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º –∫–ª–∞—Å—Å–æ–º –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
4. –§–∞–π–ª 'validation_report.txt' —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
5. –§–∞–π–ª 'predictions_detailed.json' —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
""")

    print("=" * 70)


if __name__ == "__main__":
    main()